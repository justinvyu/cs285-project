{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import multiworld\n",
    "multiworld.register_pygame_envs()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# seed_dir = Path(\"/home/justinvyu/doodad-logs/20-12-12-goal-explore-sac-env=Point2DRooms-v0-goal-generation-type=EmpowermentGoalGenerator/20-12-12-goal_explore_sac-env=Point2DRooms-v0-goal_generation_type=EmpowermentGoalGenerator_2020_12_12_01_14_56_id238392--s549525\")\n",
    "\n",
    "# Rooms\n",
    "# alpha=-1, temp=0.5\n",
    "seed_dir = Path(\"/home/justinvyu/doodad-logs/20-12-13-gc-explore-sac-env=Point2DRooms-v0-goal-generator=EmpowermentGoalGenerator/20-12-13-gc_explore_sac-env=Point2DRooms-v0-goal_generator=EmpowermentGoalGenerator_2020_12_13_03_07_56_id480574--s881561\")\n",
    "# alpha=-0.9, temp=0.3\n",
    "# seed_dir = Path(\"/home/justinvyu/doodad-logs/20-12-13-gc-explore-sac-env=Point2DRooms-v0-goal-generator=EmpowermentGoalGenerator/20-12-13-gc_explore_sac-env=Point2DRooms-v0-goal_generator=EmpowermentGoalGenerator_2020_12_13_03_07_57_id21075--s751158\")\n",
    "\n",
    "# seed_dir = Path(\"/home/justinvyu/doodad-logs/20-12-13-gc-explore-sac-env=Point2DRooms-v0-goal-generator=EmpowermentGoalGenerator/20-12-13-gc_explore_sac-env=Point2DRooms-v0-goal_generator=EmpowermentGoalGenerator_2020_12_13_03_07_56_id480574--s881561\")\n",
    "# seed_dir = Path(\"/home/justinvyu/doodad-logs/20-12-12-sac-env=Point2DRooms-v0-count-bonus=False/20-12-12-sac-env=Point2DRooms-v0-count_bonus=False_2020_12_12_01_18_19_id116563--s216694\")\n",
    "# seed_dir = Path(\"/home/justinvyu/doodad-logs/20-12-12-sac-env=Point2DRooms-v0-count-bonus=False/20-12-12-sac-env=Point2DRooms-v0-count_bonus=False_2020_12_12_01_18_19_id178772--s136223\")\n",
    "# count_based_seeds = list(glob.iglob(\"/home/justinvyu/doodad-logs/20-12-12-sac-env=Point2DRooms-v0-count-bonus=True/*\"))\n",
    "# seed_dir = Path(count_based_seeds[1])\n",
    "\n",
    "# Medium\n",
    "# seed_dir = \"/home/justinvyu/doodad-logs/20-12-13-gc-explore-sac-env=Point2DMazeEvalMedium-v0-goal-generator=EmpowermentGoalGenerator/20-12-13-gc_explore_sac-env=Point2DMazeEvalMedium-v0-goal_generator=EmpowermentGoalGenerator_2020_12_13_16_11_07_id670488--s285483\"\n",
    "# seed_dir = \"/home/justinvyu/doodad-logs/20-12-13-gc-explore-sac-env=Point2DMazeEvalMedium-v0-goal-generator=EmpowermentGoalGenerator/20-12-13-gc_explore_sac-env=Point2DMazeEvalMedium-v0-goal_generator=EmpowermentGoalGenerator_2020_12_13_16_11_08_id823533--s385839/\"\n",
    "\n",
    "# Hard\n",
    "# seed_dir = \"/home/justinvyu/doodad-logs/20-12-13-gc-explore-sac-env=Point2DMazeEvalHard-v0-goal-generator=EmpowermentGoalGenerator/20-12-13-gc_explore_sac-env=Point2DMazeEvalHard-v0-goal_generator=EmpowermentGoalGenerator_2020_12_13_16_11_07_id206029--s553639\"\n",
    "# seed_dir = \"/home/justinvyu/doodad-logs/20-12-13-gc-explore-sac-env=Point2DMazeEvalHard-v0-goal-generator=EmpowermentGoalGenerator/20-12-13-gc_explore_sac-env=Point2DMazeEvalHard-v0-goal_generator=EmpowermentGoalGenerator_2020_12_13_16_11_08_id546231--s584683\"\n",
    "\n",
    "# Unsupervised Exploration\n",
    "# seed_dir = \"/home/justinvyu/doodad-logs/20-12-15-gc-explore-sac-env=Point2DRoomsExplore-v0-goal-generator=EmpowermentGoalGenerator-schedule=constant-1\"\n",
    "# seed_dir = \"/home/justinvyu/doodad-logs/20-12-15-gc-explore-sac-env=Point2DRoomsExplore-v0-goal-generator=OracleSkewFitGoalGenerator-schedule=constant-1\"\n",
    "# seed_dir = \"/home/justinvyu/doodad-logs/20-12-15-gc-explore-sac-env=Point2DRoomsExplore-v0-goal-generator=RandomGoalGenerator-schedule=constant-1\"\n",
    "# seed_dir = \"/home/justinvyu/doodad-logs/20-12-15-gc-explore-sac-env=Point2DRoomsExplore-v0-goal-generator=RewardGoalGenerator-schedule=constant-1\"\n",
    "# seed_dir = Path(list(glob.iglob(str(Path(seed_dir) / \"*\")))[0])\n",
    "\n",
    "# No count-bonus Rooms\n",
    "# seed_dir = \"/home/justinvyu/doodad-logs/20-12-14-sac-env=Point2DRooms-v0-count-bonus=False/20-12-14-sac-env=Point2DRooms-v0-count_bonus=False_2020_12_14_21_44_03_id38488--s295432\"\n",
    "# count bonus rooms\n",
    "# seed_dir = \"/home/justinvyu/doodad-logs/20-12-16-sac-env=Point2DRooms-v0-count-bonus=True/20-12-16-sac-env=Point2DRooms-v0-count_bonus=True_2020_12_16_02_29_36_id714939--s696974\"\n",
    "\n",
    "# count double maze\n",
    "# seed_dir = \"/home/justinvyu/doodad-logs/20-12-16-sac-env=Point2DDoubleMazeSingleGoalEval-v0-count-bonus=True/20-12-16-sac-env=Point2DDoubleMazeSingleGoalEval-v0-count_bonus=True_2020_12_16_02_29_36_id605570--s461429\"\n",
    "\n",
    "seed_dir = Path(seed_dir)\n",
    "\n",
    "ckpt_paths = list(glob.iglob(str(seed_dir / \"itr*\")))\n",
    "ckpt_paths.sort(key=lambda d: int(d.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]))\n",
    "ckpts = [int(d.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]) for d in ckpt_paths]\n",
    "\n",
    "START = 390\n",
    "END = 400\n",
    "ANALYZE_EVERY_N_CKPTS = 1\n",
    "sample_grid = True\n",
    "include_skewfit_goals = False\n",
    "skewfit_alpha = -1\n",
    "generate_gif = True\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \"0.9\", \"axes.grid\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_h = None\n",
    "gif_imgs = []\n",
    "visitation_percents = [[0, 0]]\n",
    "\n",
    "ckpts_to_check = [ckpt for ckpt in ckpts if ckpt >= START and ckpt <= END]\n",
    "print(ckpts_to_check)\n",
    "ckpt_paths_to_check = [path for i, path in enumerate(ckpt_paths) if ckpts[i] >= START and ckpts[i] <= END]\n",
    "\n",
    "for i, (ckpt, ckpt_path) in enumerate(zip(ckpts_to_check, ckpt_paths_to_check)):\n",
    "    if i % ANALYZE_EVERY_N_CKPTS != 0 or i == 0:\n",
    "        continue\n",
    "            \n",
    "    with open(ckpt_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    env = data[\"exploration/env\"]\n",
    "    gc_model = None\n",
    "    goals = None\n",
    "    if \"exploration/gaussian_channel_model\" in data:\n",
    "        gc_model = data[\"exploration/gaussian_channel_model\"]\n",
    "        gc_model.to(\"cpu\")\n",
    "        training_loss_history = data[\"exploration/training_loss_history\"]\n",
    "    if \"exploration/goal_history_per_epoch\" in data:\n",
    "        goal_history = data[\"exploration/goal_history_per_epoch\"]\n",
    "        goals = np.concatenate([goals for goals in goal_history[ckpts[i - 1]:ckpt] if len(goals) > 0])\n",
    "\n",
    "    obs = data[\"replay_buffer/observations\"][\"observation\"]\n",
    "    \n",
    "    obs_d = env._discretize_observation(obs)\n",
    "    env.bin_counts = np.ones_like(env.bin_counts)\n",
    "    env.bin_counts[obs_d[:, 0], obs_d[:, 1]] += 1\n",
    "\n",
    "    fig = plt.figure(figsize=(3 * 8, 8))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Plot emopwerment training history\n",
    "#     if training_loss_history:\n",
    "#         plt.subplot(1, 3, 1)\n",
    "#         plt.title(\"Empowerment Gaussian Channel Model Training Loss\")\n",
    "#         plt.ylabel(\"MSE Loss\")\n",
    "#         plt.xlabel(\"# Gradient Steps\")\n",
    "#         plt.plot(training_loss_history)\n",
    "\n",
    "    # Generate skewfit goals\n",
    "    bin_counts = env.bin_counts[obs_d[:, 0], obs_d[:, 1]]\n",
    "    skewed_goal_densities = np.power(bin_counts, skewfit_alpha)\n",
    "    skewed_goal_probs = skewed_goal_densities / np.sum(skewed_goal_densities)\n",
    "    skewfit_goal_idxs = np.random.choice(np.arange(obs.shape[0]), p=skewed_goal_probs, size=50)\n",
    "    skewfit_goals = obs[skewfit_goal_idxs]\n",
    "    \n",
    "    if ckpt > 0:\n",
    "        # Plot visitation & goal selections\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(\n",
    "            env.render(mode='rgb_array', width=32, height=32),\n",
    "            extent=(-env.boundary_dist, env.boundary_dist, -env.boundary_dist, env.boundary_dist),\n",
    "            origin='lower', alpha=0.25, zorder=3\n",
    "        )\n",
    "\n",
    "        h, *_ = plt.hist2d(\n",
    "            obs[:, 0], obs[:, 1],\n",
    "            range=[[-env.boundary_dist, env.boundary_dist], [-env.boundary_dist, env.boundary_dist]],\n",
    "            bins=50,\n",
    "            cmap=\"inferno\",\n",
    "        )\n",
    "        plt.colorbar()\n",
    "\n",
    "#         plt.scatter(env._target_position[0], env._target_position[1], marker=\"*\", color=\"gold\", s=300, label=\"Target\")\n",
    "        \n",
    "#         if goals is not None:\n",
    "#             plt.scatter(goals[:, 0], goals[:, 1], marker=\"+\", color=\"red\", s=200, label=\"Chosen Goals\")\n",
    "        if include_skewfit_goals:\n",
    "            plt.scatter(skewfit_goals[:, 0], skewfit_goals[:, 1], marker=\"x\", color=\"green\", s=150, label=\"SkewFit Goals\")\n",
    "        plt.legend(loc='upper left', bbox_to_anchor=(0, -0.08))\n",
    "\n",
    "        plt.title(f\"Iteration {ckpt} Visitation Frequency\")\n",
    "        plt.xlim(-env.boundary_dist, env.boundary_dist)\n",
    "        plt.ylim(-env.boundary_dist, env.boundary_dist)\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(\n",
    "            env.render(mode='rgb_array', width=32, height=32),\n",
    "            extent=(-env.boundary_dist, env.boundary_dist, -env.boundary_dist, env.boundary_dist),\n",
    "            origin='lower', alpha=1, zorder=3\n",
    "        )\n",
    "        plt.imshow(\n",
    "            (h - (prev_h if prev_h is not None else np.zeros_like(h)) > 0).T.astype(int),\n",
    "            extent=(-env.boundary_dist, env.boundary_dist, -env.boundary_dist, env.boundary_dist),\n",
    "            origin='lower', alpha=0.5, zorder=3\n",
    "        )\n",
    "        visitation_percents.append([ckpt, ((h > 0).sum()) / h.size])\n",
    "        prev_h = h\n",
    "        plt.title(\"State Coverage\")\n",
    "        plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Plot empowerment\n",
    "    if gc_model is not None:\n",
    "        plt.subplot(1, 3, 3)\n",
    "\n",
    "        plt.imshow(\n",
    "            env.render(mode='rgb_array', width=32, height=32),\n",
    "            origin='lower', extent=(-env.boundary_dist, env.boundary_dist, -env.boundary_dist, env.boundary_dist), alpha=1.0)\n",
    "\n",
    "        if sample_grid:\n",
    "            x = np.linspace(-env.boundary_dist, env.boundary_dist, 32)\n",
    "            y = np.linspace(-env.boundary_dist, env.boundary_dist, 32)\n",
    "            xv, yv = np.meshgrid(x, y)\n",
    "            xys = np.hstack([xv.reshape(-1, 1), yv.reshape(-1, 1)])\n",
    "            empowerment_vals = gc_model.empowerment(xys)\n",
    "        else:\n",
    "            xys = data[\"replay_buffer/observations\"][\"observation\"]\n",
    "            xs, ys = obs[:, 0], obs[:, 1]\n",
    "\n",
    "        empowerment_vals = gc_model.empowerment(xys)\n",
    "\n",
    "        # Normalize the empowerment estimates\n",
    "        empowerment_vals = (empowerment_vals - empowerment_vals.mean()) / empowerment_vals.std()\n",
    "\n",
    "        xs, ys = xys[:, 0], xys[:, 1]\n",
    "        plt.tricontourf(xs, ys, empowerment_vals, 30, alpha=0.8, cmap=\"viridis\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        if ckpt > 0:\n",
    "            plt.scatter(goals[:128, 0], goals[:128, 1], marker=\"+\", color=\"red\", s=200, label=\"Chosen Goals\")\n",
    "            if include_skewfit_goals:\n",
    "                plt.scatter(skewfit_goals[:, 0], skewfit_goals[:, 1], marker=\"x\", color=\"green\", s=150, label=\"SkewFit Goals\")\n",
    "\n",
    "        max_idx = np.argmax(empowerment_vals)\n",
    "        min_idx = np.argmin(empowerment_vals)\n",
    "        plt.scatter(xys[max_idx, 0], xys[max_idx, 1], color=\"red\", marker=\"*\", s=300, label=\"Max Empowerment\", edgecolors='b')\n",
    "        plt.scatter(xys[min_idx, 0], xys[min_idx, 1], color=\"orange\", marker=\"*\", s=300, label=\"Min Empowerment\", edgecolors='b')\n",
    "\n",
    "        plt.legend(loc='upper left', bbox_to_anchor=(0, -0.08))\n",
    "        plt.xlim(-env.boundary_dist, env.boundary_dist)\n",
    "        plt.ylim(-env.boundary_dist, env.boundary_dist)\n",
    "        plt.title(f\"Empowerment Estimates\\nN={gc_model.N}, lr={gc_model.learning_rate}, l2_lambda={gc_model.l2_lambda}\")\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "    if generate_gif:\n",
    "        fig.canvas.draw()\n",
    "        fig_data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "        fig_data = fig_data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        gif_imgs.append(fig_data)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(\n",
    "    env.render(mode='rgb_array', width=32, height=32),\n",
    "    extent=(-env.boundary_dist, env.boundary_dist, -env.boundary_dist, env.boundary_dist),\n",
    "    origin='lower', alpha=1, zorder=3\n",
    ")\n",
    "plt.imshow(\n",
    "    (h > 0).T.astype(int),\n",
    "    extent=(-env.boundary_dist, env.boundary_dist, -env.boundary_dist, env.boundary_dist),\n",
    "    origin='lower', alpha=0.5, zorder=3\n",
    ")\n",
    "prev_h = h\n",
    "plt.title(\"All Iterations State Coverage\")\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bonus_vis = np.array(visitation_percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_vis = np.array(visitation_percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_plot = np.concatenate([[0], empowerment_visitation_percents[:, 0]])\n",
    "emp_vis = np.concatenate([[0], empowerment_visitation_percents[:, 1]])\n",
    "sk_vis = np.concatenate([[0], skewfit_visitation_percents[:, 1]])\n",
    "rnd_vis = np.concatenate([[0], random_visitation_percents[:, 1]])\n",
    "\n",
    "plt.plot(np.concatenate([[0], empowerment_visitation_percents[:, 0]]), emp_vis, label=\"Empowerment\")\n",
    "plt.plot(np.concatenate([[0], skewfit_visitation_percents[:, 0]]), np.concatenate([[0], skewfit_visitation_percents[:, 1]]), label=\"SkewFit\")\n",
    "plt.plot(np.concatenate([[0], random_visitation_percents[:, 0]]), np.concatenate([[0], random_visitation_percents[:, 1]]), label=\"Random\")\n",
    "plt.legend()\n",
    "plt.title(\"Percent of States Explored\")\n",
    "plt.xlabel(\"Iteration (1000 timesteps each)\")\n",
    "plt.ylabel(\"State Coverage (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.mimsave('./medium_maze_empowerment.gif', gif_imgs, duration=0.1 * len(gif_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "# rc('text', usetex=True)\n",
    "\n",
    "#sns.set_style(\"whitegrid\")\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \"0.9\"})\n",
    "sns.despine(left=True)\n",
    "\n",
    "def smooth(scalars, weight):  # Weight between 0 and 1\n",
    "    last = scalars[0]  # First value in the plot (first timestep)\n",
    "    smoothed = list()\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  # Calculate smoothed value\n",
    "        smoothed.append(smoothed_val)                        # Save it\n",
    "        last = smoothed_val                                  # Anchor the last smoothed value\n",
    "    return smoothed\n",
    "\n",
    "def plot(xs, ys, legend_names, file_name, xlim=None, ylim=(-0.01, 1.01),\n",
    "         xlabel=\"Iterations\", ylabel=\"Success\", title=\"\", smoothing_weight=0.9):\n",
    "    colors = sns.color_palette()\n",
    "    colors.pop(-2)\n",
    "    colors.pop(1)\n",
    "    colors.insert(-1, (242/255, 121/255, 53/255))\n",
    "    sns.palplot(colors)\n",
    "    palette = itertools.cycle(colors)\n",
    "    fontsize = 20\n",
    "    \n",
    "    plt.figure(figsize=(8, 6), dpi=160)\n",
    "    for i, (x, y) in enumerate(zip(xs, ys)):\n",
    "        c = next(palette)\n",
    "        lw = 2\n",
    "#         if i <= 2:\n",
    "#             lw = 2\n",
    "#         else:\n",
    "#             lw = 1.5\n",
    "        plt.plot(x, y, linewidth=lw, color=c)        \n",
    "#         mean, std = np.mean(y, axis=0), np.std(y, axis=0)\n",
    "\n",
    "\n",
    "#         below, above = mean - std, mean + std\n",
    "\n",
    "#         plt.plot(x, smooth(mean, smoothing_weight), linewidth=lw, color=c)\n",
    "#         plt.fill_between(x, smooth(below, smoothing_weight), smooth(above, smoothing_weight), color=c, alpha=0.1)\n",
    "\n",
    "    plt.title(title, fontsize=fontsize)\n",
    "    plt.xlabel(xlabel, fontsize=fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=fontsize)\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    legend = plt.legend(legend_names,\n",
    "               frameon=True, facecolor='w', framealpha=0.9, shadow=True, fontsize=fontsize-5,\n",
    "#                loc='upper center', ncol=4) # right legend\n",
    "#                loc='center left', bbox_to_anchor=(1, 0.5), ncol=1) # right legend\n",
    "               loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3) # bottom legend\n",
    "    legend.get_frame().set_linewidth(1.5)\n",
    "    legend.get_frame().set_edgecolor(\"black\")\n",
    "#     plt.savefig(\"./test.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./unsupervised_expl.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "xs = data[\"ckpts\"]\n",
    "emp = data[\"empowerment\"]\n",
    "sk = data[\"skewfit\"]\n",
    "rnd = data[\"random\"]\n",
    "\n",
    "legend_names = [\"Empowerment\", \"SkewFit\", \"Random\", \"No Goals\", \"No Goals + Count Bonus\"]\n",
    "plot([xs, xs, xs, sac_vis[:, 0], count_bonus_vis[:, 0]], [emp, sk, rnd, sac_vis[:, 1], count_bonus_vis[:, 1]], legend_names, \"\", title=\"Percentage of States Explored\", xlabel=\"Iteration (1000 timesteps each)\", ylabel=\"State Coverage (%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Goal Sampling Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_obs = env._discretize_observation(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_obs = env._discretize_observation(obs)\n",
    "env.bin_counts = np.ones_like(env.bin_counts)\n",
    "for o in discrete_obs:\n",
    "    env.bin_counts[o[0], o[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(env.bin_counts)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_counts = env.bin_counts[discrete_obs[:, 0], discrete_obs[:, 1]]\n",
    "skewed_goal_densities = np.power(bin_counts, -1)\n",
    "\n",
    "# Normalize to a proper probability distribution\n",
    "skewed_goal_probs = skewed_goal_densities / np.sum(skewed_goal_densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-env.boundary_dist, env.boundary_dist, 32)\n",
    "y = np.linspace(-env.boundary_dist, env.boundary_dist, 32)\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "xys = np.hstack([xv.reshape(-1, 1), yv.reshape(-1, 1)])\n",
    "empowerment_vals = gc_model.empowerment(xys)\n",
    "normalized_empowerment_vals = (empowerment_vals - empowerment_vals.mean()) / empowerment_vals.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    bin_counts = env.bin_counts[discrete_obs[:, 0], discrete_obs[:, 1]]\n",
    "    skewed_goal_densities = np.power(bin_counts, -1)\n",
    "\n",
    "    # Normalize to a proper probability distribution\n",
    "    skewed_goal_probs = skewed_goal_densities / np.sum(skewed_goal_densities)\n",
    "    candidate_idxs = np.random.choice(np.arange(discrete_obs.shape[0]), p=skewed_goal_probs, size=50)\n",
    "    goals = obs[candidate_idxs]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    plt.imshow(\n",
    "        env.render(mode='rgb_array', width=32, height=32),\n",
    "        extent=(-env.boundary_dist, env.boundary_dist, -env.boundary_dist, env.boundary_dist),\n",
    "        origin='lower', alpha=0.25, zorder=3\n",
    "    )\n",
    "\n",
    "    plt.hist2d(\n",
    "        obs[:, 0], obs[:, 1],\n",
    "        range=[[-env.boundary_dist, env.boundary_dist], [-env.boundary_dist, env.boundary_dist]],\n",
    "        bins=50\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    plt.scatter(env._target_position[0], env._target_position[1], marker=\"*\", color=\"gold\", s=300, label=\"Target\")\n",
    "\n",
    "    plt.scatter(goals[:, 0], goals[:, 1], marker=\"x\", color=\"green\", s=150, label=\"SkewFit Goals\")\n",
    "\n",
    "    plt.title(f\"Iteration {ckpt} Visitation Frequency\")\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(0, -0.08))\n",
    "    plt.xlim(-env.boundary_dist, env.boundary_dist)\n",
    "    plt.ylim(-env.boundary_dist, env.boundary_dist)\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([0, 0, 0, 0])\n",
    "\n",
    "def modify_test():\n",
    "    return {'a': test[:]}\n",
    "\n",
    "d = modify_test()\n",
    "d[\"a\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rlkit.misc.pytorch_util as ptu\n",
    "device = ptu.init_gpu(use_gpu=True)\n",
    "gc_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_with_gpu():\n",
    "    device = ptu.init_gpu(use_gpu=True)\n",
    "    gc_model.to(device)\n",
    "    start = time.time()\n",
    "    emp_vals = gc_model.empowerment(ptu.from_numpy(obs[:500]))\n",
    "    elapsed = time.time() - start\n",
    "    return elapsed\n",
    "\n",
    "def time_with_cpu():\n",
    "#     device = ptu.init_gpu(use_gpu=False)\n",
    "    gc_model.to(\"cpu\")\n",
    "    start = time.time()\n",
    "    emp_vals = gc_model.empowerment(obs[:500])\n",
    "    elapsed = time.time() - start\n",
    "    return elapsed\n",
    "\n",
    "t_gpu = time_with_gpu()\n",
    "t_cpu = time_with_cpu()\n",
    "\n",
    "print(f\"gpu = {t_gpu}, cpu = {t_cpu}, gpu = {t_gpu / t_cpu} * cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
